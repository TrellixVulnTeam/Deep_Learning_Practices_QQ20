- activation: relu
  augmentation: true
  batch_size: 8
  hidden_layers: [100, 50]
  img_size: 64
  initialization: null
  learning_rate: 0.001
  n_classes: 6
  n_epochs: 400
  print_every: 10
